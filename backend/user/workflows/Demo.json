{
  "nodes": [
    {
      "id": "ConnectRobotNode-1752694507773",
      "type": "customNode",
      "position": {
        "x": 90.30782309921378,
        "y": 439.17723614370817
      },
      "data": {
        "label": "Connect Robot",
        "nodeInfo": {
          "name": "ConnectRobotNode",
          "display_name": "Connect Robot",
          "description": "Connect to a robot using ScsServoSDK.connect() and return SDK instance",
          "detailed_description": "\nConnectRobotNode\n\nPurpose: Establishes a connection to a robot using the ScsServoSDK and returns the SDK instance for use by other robot nodes.\n\nInputs:\n  - port_name (STRING): The serial port name to connect to (leave empty for auto-detection)\n\nOutputs:\n  - sdk (ScsServoSDK): The connected SDK instance that can be used by other robot control nodes\n\nUsage: Use this node at the beginning of robot workflows to establish communication. The SDK output should be connected to other robot nodes that require servo control. If port_name is empty, the system will attempt to auto-detect the robot.\n        ",
          "category": "robot",
          "input_types": {
            "required": {
              "port_name": [
                "STRING",
                {
                  "default": ""
                }
              ]
            }
          },
          "return_types": {
            "required": {
              "sdk": [
                "ScsServoSDK",
                {}
              ]
            }
          },
          "function": "connect_robot"
        },
        "type": "ConnectRobotNode",
        "inputValues": {
          "port_name": "/dev/tty.usbmodem5A7A0558831"
        }
      },
      "width": 280,
      "height": 137,
      "selected": false,
      "positionAbsolute": {
        "x": 159.47660885213043,
        "y": 332.0082989099732
      },
      "dragging": false,
      "measured": {
        "width": 280,
        "height": 137
      }
    },
    {
      "id": "SO101RobotStatusReader-1752985250384",
      "type": "customNode",
      "position": {
        "x": 451.2882514054527,
        "y": 449.12360660174016
      },
      "data": {
        "label": "SO101 Robot Status Reader",
        "nodeInfo": {
          "name": "SO101RobotStatusReader",
          "display_name": "SO101 Robot Status Reader",
          "description": "Read status (positions, modes) from connected robot servos using feetech-servo-sdk",
          "detailed_description": "\n            RobotStatusReader Node\n\n            Purpose: Reads status (positions, modes) from connected robot servos using feetech-servo-sdk.\n\n            Inputs:\n              - sdk (ScsServoSDK): The SDK instance for communicating with servos.\n\n            Outputs:\n              - status_data (DICT): Dictionary containing read positions, modes, servo_ids, timestamp, and connection status.\n              - positions (DICT): Dictionary of servo positions keyed by servo ID.\n\n            Features:\n              - Automatically reads positions for servos 1-6\n              - Reads servo modes for each connected servo\n              - Provides timestamp and connection status information\n              - Handles errors gracefully with detailed error messages\n              - Returns both comprehensive status data and positions separately\n\n            Usage:\n              - Connect the ScsServoSDK output from a robot connection node\n              - The node automatically reads from servos 1-6\n              - Use status_data for comprehensive robot state information\n              - Use positions for direct access to servo position values\n              - Monitor connection status and error handling\n            ",
          "tags": [
            "SO101",
            "SO100"
          ],
          "input_types": {
            "required": {
              "sdk": [
                "ScsServoSDK",
                {}
              ]
            },
            "optional": {}
          },
          "return_types": {
            "required": {
              "status_data": [
                "DICT",
                {}
              ],
              "positions": [
                "DICT",
                {}
              ]
            }
          },
          "function": "read_robot_status"
        },
        "type": "SO101RobotStatusReader",
        "bypassed": false
      },
      "measured": {
        "width": 479,
        "height": 296
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "ThreeDVisualizationNode-1753835857504",
      "type": "threeDNode",
      "position": {
        "x": 1160.8672703198586,
        "y": 317.7326218730983
      },
      "data": {
        "label": "3D Visualization",
        "nodeInfo": {
          "name": "ThreeDVisualizationNode",
          "display_name": "3D Visualization",
          "description": "Visualize robot positions in 3D by converting motor positions to angles.",
          "detailed_description": "\nThreeDVisualizationNode\n\nPurpose: Takes motor position data and converts it to joint angles for 3D visualization. This node processes motor position data and returns visualization data that can be rendered in a 3D viewer.\n\nInputs:\n  - positions (DICT): Dictionary mapping servo IDs to positions in format:\n    {1: 1510, 2: 1029, 3: 3010, 4: 967, 5: 638, 6: 2039}\n\nOutputs:\n  - None (produces rt_update for 3D visualization)\n\nUsage: Use this node to visualize robot joint states in 3D. Connect it to nodes that provide motor position data to see the 3D representation of the robot's current configuration in the UI.\n        ",
          "tags": [
            "Basic"
          ],
          "input_types": {
            "required": {
              "positions": [
                "DICT",
                {}
              ]
            }
          },
          "return_types": {
            "required": {}
          },
          "function": "visualize_3d"
        },
        "type": "ThreeDVisualizationNode"
      },
      "measured": {
        "width": 800,
        "height": 600
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "So101WritePositionNode-1753836694409",
      "type": "customNode",
      "position": {
        "x": 729.1374708181899,
        "y": 969.0616963605294
      },
      "data": {
        "label": "SO101 Write Position",
        "nodeInfo": {
          "name": "So101WritePositionNode",
          "display_name": "SO101 Write Position",
          "description": "Write multiple servo positions to the robot using ScsServoSDK.",
          "detailed_description": "\n            So101WritePositionNode\n\n            Purpose: Writes multiple servo positions to the robot using ScsServoSDK.\n\n            Inputs:\n              - sdk (ScsServoSDK): The SDK instance for communicating with servos.\n              - positions (DICT): Dictionary mapping servo IDs to target positions (e.g., {1: 2048, 2: 1024}).\n\n            Outputs:\n              - sdk (ScsServoSDK): The SDK instance, passed through for chaining.\n              - write_result (DICT): Dictionary reflecting the positions written to the servos.\n\n            Features:\n              - Writes positions to multiple servos simultaneously\n              - Uses sync_write_positions for efficient communication\n              - Provides detailed error messages with stack traces\n              - Returns the positions that were successfully written\n              - Handles connection errors and servo communication failures\n\n            Usage:\n              - Connect the ScsServoSDK output from a robot connection node\n              - Provide positions dictionary with servo ID to position mapping\n              - The node will attempt to write all positions to the robot\n              - Monitor the write_result for confirmation of successful writes\n              - Use with position data from joint angle conversion nodes\n            ",
          "tags": [
            "SO101",
            "SO100"
          ],
          "input_types": {
            "required": {
              "sdk": [
                "ScsServoSDK",
                {}
              ],
              "positions": [
                "DICT",
                {}
              ]
            },
            "optional": {}
          },
          "return_types": {
            "required": {
              "sdk": [
                "ScsServoSDK",
                {}
              ],
              "write_result": [
                "DICT",
                {}
              ]
            }
          },
          "function": "write_positions"
        },
        "type": "So101WritePositionNode",
        "bypassed": true
      },
      "measured": {
        "width": 358,
        "height": 138
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "ConnectRobotNode-1753836697198",
      "type": "customNode",
      "position": {
        "x": 377.97561607160753,
        "y": 929.7888914781391
      },
      "data": {
        "label": "Connect Robot",
        "nodeInfo": {
          "name": "ConnectRobotNode",
          "display_name": "Connect Robot",
          "description": "Connect to a robot using ScsServoSDK.connect() and return SDK instance",
          "detailed_description": "\nConnectRobotNode\n\nPurpose: Establishes a connection to a robot using the ScsServoSDK and returns the SDK instance for use by other robot nodes.\n\nInputs:\n  - port_name (STRING): The serial port name to connect to (leave empty for auto-detection)\n\nOutputs:\n  - sdk (ScsServoSDK): The connected SDK instance that can be used by other robot control nodes\n\nUsage: Use this node at the beginning of robot workflows to establish communication. The SDK output should be connected to other robot nodes that require servo control. If port_name is empty, the system will attempt to auto-detect the robot.\n        ",
          "category": "robot",
          "input_types": {
            "required": {
              "port_name": [
                "STRING",
                {
                  "default": ""
                }
              ]
            }
          },
          "return_types": {
            "required": {
              "sdk": [
                "ScsServoSDK",
                {}
              ]
            }
          },
          "function": "connect_robot"
        },
        "type": "ConnectRobotNode",
        "inputValues": {
          "port_name": "/dev/tty.usbmodem5A7A0558831"
        },
        "bypassed": true
      },
      "width": 280,
      "height": 137,
      "selected": false,
      "positionAbsolute": {
        "x": 159.47660885213043,
        "y": 332.0082989099732
      },
      "dragging": false,
      "measured": {
        "width": 280,
        "height": 137
      }
    },
    {
      "id": "CameraNode-1753837426114",
      "type": "cameraNode",
      "position": {
        "x": -17.240656310717384,
        "y": -67.71535058431161
      },
      "data": {
        "label": "Camera",
        "nodeInfo": {
          "name": "CameraNode",
          "display_name": "Camera",
          "description": "Prompt the user to open their camera and output an image.",
          "detailed_description": "\nCameraNode\n\nPurpose: Takes a camera image stream and outputs it as an image for processing or display.\n\nInputs:\n  - image_stream (CAMERA): Camera image stream data from the frontend\n\nOutputs:\n  - image (IMAGE): The image from the camera stream\n\nUsage: Use this node to capture and process images from a camera. Connect it to camera input from the frontend to get live image data for further processing or display.\n        ",
          "tags": [
            "Basic"
          ],
          "input_types": {
            "required": {
              "image_stream": [
                "CAMERA",
                {}
              ]
            }
          },
          "return_types": {
            "required": {
              "image": [
                "IMAGE",
                {}
              ]
            }
          },
          "function": "open_camera"
        },
        "type": "CameraNode",
        "bypassed": false
      },
      "measured": {
        "width": 339,
        "height": 354
      },
      "selected": true,
      "dragging": false
    },
    {
      "id": "VLMNode-1753837540374",
      "type": "customNode",
      "position": {
        "x": 481.79876899094063,
        "y": -84.64065139510627
      },
      "data": {
        "label": "VLM",
        "nodeInfo": {
          "name": "VLMNode",
          "display_name": "VLM",
          "description": "Grok VLM",
          "detailed_description": "\nVLMNode\n\nPurpose: Mock Vision Language Model node that processes images with text prompts.\n\nInputs:\n  - system_prompt (STRING): The system prompt for the VLM (default: empty string)\n  - images (IMAGE): The images to process with the VLM\n\nOutputs:\n  - response (STRING): The VLM's response to the prompt and images\n  - confidence (FLOAT): Confidence score of the response\n\nUsage: Use this node to simulate VLM processing. The node will pass through the inputs and return mock responses.\n        ",
          "tags": [
            "Basic"
          ],
          "input_types": {
            "required": {
              "system_prompt": [
                "STRING",
                {
                  "default": ""
                }
              ],
              "user_prompt": [
                "STRING",
                {
                  "default": ""
                }
              ],
              "model_name": [
                "STRING",
                {
                  "default": "grok-vlm"
                }
              ],
              "images": [
                "IMAGE",
                {}
              ]
            }
          },
          "return_types": {
            "required": {
              "immediate_action": [
                "STRING",
                {}
              ]
            }
          },
          "function": "process_vlm"
        },
        "type": "VLMNode",
        "inputValues": {
          "system_prompt": "As a robotic operations specialist, your task is to take complex procedures and break them down into a series of discrete, one-step movements. Each movement should be clearly defined, simple to execute, and logically sequenced to ensure smooth operation. The goal is to deconstruct intricate tasks into manageable actions that the robot can perform in a sequence of mechanic movements with precision and accuracy.",
          "user_prompt": "Pick up the bottle on the table.",
          "model_name": "llava"
        },
        "bypassed": true
      },
      "measured": {
        "width": 349,
        "height": 526
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "VLAModelNode-1753837565136",
      "type": "customNode",
      "position": {
        "x": 1086.269058792949,
        "y": -53.011392045001145
      },
      "data": {
        "label": "VLA Model",
        "nodeInfo": {
          "name": "VLAModelNode",
          "display_name": "VLA Model",
          "description": "VLA node",
          "detailed_description": "\nVLAModelNode\n\nPurpose: Mock Vision Language Action model node that processes system status, prompts, and images to generate actions.\n\nInputs:\n  - system_status (DICT): Current system status information\n  - prompt (STRING): The prompt for the VLA model (default: empty string)\n  - images (IMAGE): The images to process with the VLA model\n\nOutputs:\n  - action (STRING): The action to be performed\n  - parameters (DICT): Parameters for the action\n  - confidence (FLOAT): Confidence score of the action\n\nUsage: Use this node to simulate VLA model processing. The node will pass through the inputs and return mock actions and parameters.\n        ",
          "tags": [
            "Basic"
          ],
          "input_types": {
            "required": {
              "system_status": [
                "DICT",
                {}
              ],
              "prompt": [
                "STRING",
                {
                  "default": ""
                }
              ],
              "images": [
                "IMAGE",
                {}
              ],
              "model_name": [
                "STRING",
                {
                  "default": "grok-vla"
                }
              ]
            }
          },
          "return_types": {
            "required": {
              "desired_positions": [
                "DICT",
                {}
              ]
            }
          },
          "function": "process_vla"
        },
        "type": "VLAModelNode",
        "inputModes": {
          "prompt": "connection"
        },
        "inputValues": {
          "model_name": "SmolVLA"
        },
        "bypassed": true
      },
      "measured": {
        "width": 366,
        "height": 264
      },
      "selected": false,
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "ConnectRobotNode-1752694507773",
      "sourceHandle": "output",
      "target": "SO101RobotStatusReader-1752985250384",
      "targetHandle": "sdk",
      "id": "xy-edge__ConnectRobotNode-1752694507773output-SO101RobotStatusReader-1752985250384sdk",
      "className": ""
    },
    {
      "source": "SO101RobotStatusReader-1752985250384",
      "sourceHandle": "output-1",
      "target": "ThreeDVisualizationNode-1753835857504",
      "targetHandle": "positions",
      "id": "xy-edge__SO101RobotStatusReader-1752985250384output-1-ThreeDVisualizationNode-1753835857504positions",
      "className": ""
    },
    {
      "source": "ConnectRobotNode-1753836697198",
      "sourceHandle": "output",
      "target": "So101WritePositionNode-1753836694409",
      "targetHandle": "sdk",
      "id": "xy-edge__ConnectRobotNode-1753836697198output-So101WritePositionNode-1753836694409sdk",
      "className": ""
    },
    {
      "source": "CameraNode-1753837426114",
      "sourceHandle": "output",
      "target": "VLMNode-1753837540374",
      "targetHandle": "images",
      "id": "xy-edge__CameraNode-1753837426114output-VLMNode-1753837540374images",
      "className": ""
    },
    {
      "source": "SO101RobotStatusReader-1752985250384",
      "sourceHandle": "output-0",
      "target": "VLAModelNode-1753837565136",
      "targetHandle": "system_status",
      "id": "xy-edge__SO101RobotStatusReader-1752985250384output-0-VLAModelNode-1753837565136system_status",
      "className": ""
    },
    {
      "source": "CameraNode-1753837426114",
      "sourceHandle": "output",
      "target": "VLAModelNode-1753837565136",
      "targetHandle": "images",
      "id": "xy-edge__CameraNode-1753837426114output-VLAModelNode-1753837565136images",
      "className": ""
    },
    {
      "source": "VLMNode-1753837540374",
      "sourceHandle": "output",
      "target": "VLAModelNode-1753837565136",
      "targetHandle": "prompt",
      "id": "xy-edge__VLMNode-1753837540374output-VLAModelNode-1753837565136prompt",
      "className": ""
    }
  ],
  "metadata": {
    "name": "Demo",
    "description": "Workflow saved on 7/29/2025",
    "created": "2025-07-30T01:16:29.993Z",
    "version": "1.0.0",
    "modified": "2025-07-30T01:16:29.993Z"
  }
}